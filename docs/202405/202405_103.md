# OpenAI 发布旗舰模型 GPT-4o，实现实时音频、视觉和文本推理

> 原文：[`www.yuque.com/for_lazy/wind/sgs4c3xnqlyo0mz2`](https://www.yuque.com/for_lazy/wind/sgs4c3xnqlyo0mz2)

作者： 阿牛

日期：2024-05-14

点赞数：**63**

* * *

正文：

### 标题：Hello GPT-4o | OpenAI #### 日期：2024 年 5 月 13 日 ##### 宣布 -

**GPT-4o**：OpenAI 的新旗舰模型，能够实时地进行音频、视觉和文本推理。 ##### 贡献 - 尝试使用**ChatGPT**。 -
在**Playground**中尝试。 - 重新观看现场演示。 ##### 特点 -
**GPT-4o**（"o"代表"omni"）：旨在实现更自然的人机交互。 - 输入：接受文本、音频和图像的任何组合。 -
输出：生成文本、音频和图像的任何组合。 - 响应时间：音频输入响应时间短至 232 毫秒，平均 320 毫秒，与人类对话响应时间相似。 -
性能：在英文文本和代码上与 GPT-4 Turbo 相当，在非英文语言上有显著提升，API 速度更快，价格更便宜（50%）。 -
视觉和音频理解：相比现有模型有显著提升。 ##### 功能 - 两个 GPT-4o 互动和唱歌。 - 面试准备。 - 剪刀石头布游戏。 - 理解讽刺。
- 数学问题解答。 - 和谐两个 GPT-4o。 - 学习西班牙语。 - 会见人工智能。 - 实时翻译。 - 摇篮曲。 - 加快速度说话。 -
唱“生日快乐”。 - 谈论狗。 - 讲爸爸笑话。 - 与伦敦 BeMyEyes 的 Andy 互动。 - 客户服务概念验证。 ##### 能力探索 -
展示了 GPT-4o 处理文本、视觉和音频输入输出的示例。 ##### 模型评估 - 在文本、推理和编码智能方面达到 GPT-4 Turbo 级性能。 -
在多语言、音频和视觉功能方面创下新高。 ##### 语言标记化 - 展示了新标记器在不同语言家族中的压缩效果。 ##### 安全性和局限性 -
通过过滤训练数据和后训练改进模型行为等技术，GPT-4o 在各种模式中内置了安全性。 - 经过广泛的外部红色组队和专家评估，以识别新增加的模式所带来的风险。
- 音频模式存在新的风险，文本和图像输入以及文本输出已公开发布。 ##### 模型可用性 -
GPT-4o 是推动深度学习边界的最新一步，特别注重实用可用性。 - 文本和图像功能开始在 ChatGPT 中推出，免费提供，Plus 用户享有更高消息限制。
- 开发者可以通过 API 访问 GPT-4o 作为文本和视觉模型。 - 计划在未来几周内推出对 GPT-4o 新音频和视频功能的支持。 ##### 作者 -
OpenAI 团队成员。 ##### 功能和安全性测试 - 提供了对 GPT-4o 功能和安全性的测试结果，包括与传统基准测试的比较。 ##### 其他 -
提供了大声朗读功能。 链接地址： [`openai.com/index/hello-gpt-4o/`](https://openai.com/index/hello-gpt-4o/) 

* * *

评论区：

* * *

公众号懒人搜索，懒人专属群分享